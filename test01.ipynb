{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test01.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kochol/tf_tests/blob/master/test01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-O1bNBRsjFd",
        "colab_type": "text"
      },
      "source": [
        "# Test 01"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nc9-K9jksOT7",
        "colab_type": "text"
      },
      "source": [
        "This is the first test of my tf code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neZ_3gOysUrv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4f3ea0f7-f3b6-47b8-ddc2-f942a1778f53"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# enable tf eager execution to support iterating\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "print(tf.VERSION)\n",
        "print(tf.keras.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n",
            "2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EK5PHCxs9gL",
        "colab_type": "text"
      },
      "source": [
        "## Create the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTKd5qQds2Cy",
        "colab_type": "text"
      },
      "source": [
        "Now create the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qip2UQO5s5fJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "3222294f-d814-4d39-cf7c-b649ad705c0e"
      },
      "source": [
        "inputs = tf.keras.Input(shape=(8,))  # Returns a placeholder tensor\n",
        "\n",
        "# A layer instance is callable on a tensor, and returns a tensor.\n",
        "x = layers.Dense(64, activation='relu')(inputs)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "predictions = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=predictions)\n",
        "\n",
        "# I want to calc on float numbers so I use mse and mae for loss and metrics\n",
        "# Also I have to find out which optimizer is good for me.\n",
        "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
        "              loss='mse',\n",
        "              metrics=['mae'])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:642: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUznfhHyyMhl",
        "colab_type": "text"
      },
      "source": [
        "## Load data from csv file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LP_zhLGyQ0p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2434
        },
        "outputId": "2ce2b874-00a7-432e-e591-f560d7ba2b19"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Download mydata.csv from github\n",
        "!curl --remote-name \\\n",
        "     -H 'Accept: application/vnd.github.v3.raw' \\\n",
        "     --location https://raw.githubusercontent.com/kochol/tf_tests/master/mydata.csv\n",
        "\n",
        "# load all data\n",
        "mydata = pd.read_csv(\"mydata.csv\")\n",
        "\n",
        "print(mydata.columns)\n",
        "print(mydata.dtypes)\n",
        "print(mydata.shape)\n",
        "print(mydata)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  154k  100  154k    0     0   726k      0 --:--:-- --:--:-- --:--:--  726k\n",
            "Index(['start', 'open', 'high', 'low', 'close', 'vwp', 'volume', 'trades'], dtype='object')\n",
            "start       int64\n",
            "open      float64\n",
            "high      float64\n",
            "low       float64\n",
            "close     float64\n",
            "vwp       float64\n",
            "volume    float64\n",
            "trades      int64\n",
            "dtype: object\n",
            "(1884, 8)\n",
            "              start     open     high      low    close          vwp  \\\n",
            "0     1549572240000  3399.97  3403.31  3397.05  3397.41  3399.854913   \n",
            "1     1549575840000  3397.07  3400.00  3393.55  3399.99  3396.959966   \n",
            "2     1549579440000  3399.99  3401.80  3394.20  3395.55  3398.188483   \n",
            "3     1549583040000  3395.32  3398.71  3391.00  3394.28  3395.020762   \n",
            "4     1549586640000  3394.29  3396.00  3390.37  3390.66  3393.631389   \n",
            "5     1549590240000  3390.68  3394.88  3373.10  3394.88  3387.109557   \n",
            "6     1549593840000  3394.88  3407.78  3389.47  3405.34  3398.472222   \n",
            "7     1549597440000  3405.34  3405.59  3397.14  3401.37  3401.042204   \n",
            "8     1549601040000  3401.02  3411.00  3399.47  3408.60  3406.066170   \n",
            "9     1549604640000  3408.83  3410.24  3400.50  3406.20  3407.387864   \n",
            "10    1549608240000  3406.20  3409.94  3392.97  3398.10  3402.460301   \n",
            "11    1549611840000  3398.10  3407.10  3393.77  3405.40  3401.429192   \n",
            "12    1549615440000  3404.45  3450.50  3403.71  3434.15  3428.212014   \n",
            "13    1549619040000  3434.17  3439.38  3424.57  3430.84  3429.921471   \n",
            "14    1549622640000  3430.85  3441.79  3427.96  3429.95  3435.157432   \n",
            "15    1549626240000  3429.95  3447.99  3429.00  3434.41  3433.599318   \n",
            "16    1549629840000  3434.41  3448.00  3434.39  3441.96  3440.312870   \n",
            "17    1549633440000  3442.00  3469.89  3440.83  3447.99  3451.783367   \n",
            "18    1549637040000  3447.61  3504.90  3447.61  3487.79  3471.862623   \n",
            "19    1549640640000  3487.79  3543.00  3481.98  3534.96  3501.163181   \n",
            "20    1549644240000  3534.93  3733.58  3526.16  3647.93  3657.316525   \n",
            "21    1549647840000  3647.21  3677.65  3641.35  3655.53  3659.459819   \n",
            "22    1549651440000  3656.26  3669.08  3647.91  3666.75  3658.082434   \n",
            "23    1549655040000  3666.10  3669.99  3657.13  3666.15  3665.266219   \n",
            "24    1549658640000  3666.15  3669.92  3612.00  3641.10  3645.997903   \n",
            "25    1549662240000  3641.68  3645.00  3628.52  3634.95  3637.113281   \n",
            "26    1549665840000  3634.98  3651.64  3625.36  3647.58  3639.559211   \n",
            "27    1549669440000  3647.98  3667.89  3641.34  3648.66  3656.173091   \n",
            "28    1549673040000  3648.66  3657.48  3642.09  3642.94  3648.620409   \n",
            "29    1549676640000  3643.23  3647.51  3635.00  3647.51  3642.760715   \n",
            "...             ...      ...      ...      ...      ...          ...   \n",
            "1854  1556246640000  5478.93  5479.07  5331.23  5345.89  5390.716881   \n",
            "1855  1556250240000  5345.87  5387.92  5324.76  5341.40  5352.958369   \n",
            "1856  1556253840000  5341.29  5358.62  5305.62  5353.41  5330.396247   \n",
            "1857  1556257440000  5353.39  5356.99  5271.00  5275.89  5305.351113   \n",
            "1858  1556261040000  5274.89  5319.64  5271.00  5292.01  5298.732220   \n",
            "1859  1556264640000  5292.57  5323.35  5282.91  5313.85  5301.697690   \n",
            "1860  1556268240000  5313.82  5318.62  5293.02  5307.29  5305.528815   \n",
            "1861  1556271840000  5307.29  5338.72  5295.00  5323.26  5317.729981   \n",
            "1862  1556275440000  5325.78  5341.46  5291.23  5331.80  5321.175538   \n",
            "1863  1556279040000  5333.61  5339.55  5302.12  5325.99  5322.464091   \n",
            "1864  1556282640000  5324.50  5337.99  5303.20  5315.11  5321.298433   \n",
            "1865  1556286240000  5315.11  5317.21  5290.00  5312.86  5303.320509   \n",
            "1866  1556289840000  5313.19  5317.62  5274.00  5287.40  5299.351278   \n",
            "1867  1556293440000  5287.40  5291.47  5195.89  5238.81  5242.279601   \n",
            "1868  1556297040000  5239.94  5288.37  5227.96  5282.99  5261.229536   \n",
            "1869  1556300640000  5282.42  5285.14  5240.98  5257.39  5269.316284   \n",
            "1870  1556304240000  5255.97  5278.46  5232.61  5266.94  5258.772196   \n",
            "1871  1556307840000  5267.09  5303.99  5256.45  5292.41  5286.288981   \n",
            "1872  1556311440000  5292.41  5304.00  5257.55  5295.53  5280.833085   \n",
            "1873  1556315040000  5295.53  5340.00  5287.63  5317.34  5315.235389   \n",
            "1874  1556318640000  5318.53  5329.45  5280.00  5305.93  5306.310029   \n",
            "1875  1556322240000  5305.93  5326.12  5299.39  5302.89  5314.584360   \n",
            "1876  1556325840000  5304.17  5313.52  5290.61  5303.02  5302.214559   \n",
            "1877  1556329440000  5303.00  5311.97  5287.37  5288.63  5301.462768   \n",
            "1878  1556333040000  5288.47  5311.97  5287.00  5305.86  5299.396701   \n",
            "1879  1556336640000  5305.20  5308.23  5261.29  5277.89  5279.955049   \n",
            "1880  1556340240000  5279.46  5303.80  5273.20  5303.00  5288.731952   \n",
            "1881  1556343840000  5303.00  5320.00  5297.00  5314.62  5310.211306   \n",
            "1882  1556347440000  5313.81  5319.53  5302.68  5316.07  5312.517028   \n",
            "1883  1556351040000  5316.02  5325.59  5297.80  5301.53  5312.670450   \n",
            "\n",
            "            volume  trades  \n",
            "0       624.703200    4216  \n",
            "1       425.889042    3765  \n",
            "2       314.319555    3635  \n",
            "3       615.425010    5039  \n",
            "4       533.466124    4544  \n",
            "5      1324.826348    6920  \n",
            "6       822.655030    4968  \n",
            "7       536.712830    3580  \n",
            "8       721.437806    4669  \n",
            "9       689.959857    4244  \n",
            "10      600.438821    4556  \n",
            "11      542.116031    5001  \n",
            "12     3192.895227   16598  \n",
            "13     1494.152952    7662  \n",
            "14     1281.055066    7156  \n",
            "15     2538.108644    8658  \n",
            "16     1188.155468    7321  \n",
            "17     1681.190055    8686  \n",
            "18     2549.028245   14100  \n",
            "19     4173.019454   22399  \n",
            "20    12431.285204   53665  \n",
            "21     3141.613067   18088  \n",
            "22     2393.526405   11219  \n",
            "23     1245.848386    8048  \n",
            "24     1991.124954   14494  \n",
            "25     1074.392671    8831  \n",
            "26      899.402822    8421  \n",
            "27     1401.022075   11506  \n",
            "28     1031.366986    8919  \n",
            "29      842.202341    8218  \n",
            "...            ...     ...  \n",
            "1854   4559.789328   24015  \n",
            "1855   2146.009541   13859  \n",
            "1856   1449.036549   11746  \n",
            "1857   2037.089587   13987  \n",
            "1858   1734.696084   12422  \n",
            "1859   1375.299595   10700  \n",
            "1860   1101.579241    7567  \n",
            "1861   1990.740802   12301  \n",
            "1862   2098.179072   12441  \n",
            "1863   1522.625991   10412  \n",
            "1864   1294.030475    8015  \n",
            "1865   1302.065080    9848  \n",
            "1866   2073.062375   13968  \n",
            "1867   3664.877520   21298  \n",
            "1868   1706.641348   10554  \n",
            "1869   1138.348077    9223  \n",
            "1870   1131.830244    8888  \n",
            "1871   1249.773957    9667  \n",
            "1872   1035.697818    8434  \n",
            "1873   1040.565513    8890  \n",
            "1874    912.518227    8011  \n",
            "1875    651.033674    7180  \n",
            "1876    601.515527    6348  \n",
            "1877    527.819610    5984  \n",
            "1878    587.664093    6251  \n",
            "1879    864.168327    7558  \n",
            "1880    736.375706    5968  \n",
            "1881    774.417616    6439  \n",
            "1882    473.888057    5119  \n",
            "1883    667.898356    6173  \n",
            "\n",
            "[1884 rows x 8 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxaIDYj2Vu30",
        "colab_type": "text"
      },
      "source": [
        "Prepare the data for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgXylRmsWPPA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "outputId": "9914fc4a-546f-43a9-e910-f2bbc6917a17"
      },
      "source": [
        "train = mydata[0:-1].copy()\n",
        "print(train.columns)\n",
        "print(train.dtypes)\n",
        "print(train.shape)\n",
        "\n",
        "test = pd.DataFrame({'price': mydata[1:].close})\n",
        "print(test.columns)\n",
        "print(test.dtypes)\n",
        "print(test.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['start', 'open', 'high', 'low', 'close', 'vwp', 'volume', 'trades'], dtype='object')\n",
            "start       int64\n",
            "open      float64\n",
            "high      float64\n",
            "low       float64\n",
            "close     float64\n",
            "vwp       float64\n",
            "volume    float64\n",
            "trades      int64\n",
            "dtype: object\n",
            "(1883, 8)\n",
            "Index(['price'], dtype='object')\n",
            "price    float64\n",
            "dtype: object\n",
            "(1883, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjl8t8WE7rGh",
        "colab_type": "text"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxrRGyGj8nSQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        },
        "outputId": "d4119a88-9dcd-4c63-c75b-9dab54af0c91"
      },
      "source": [
        "train_np = train.to_numpy()\n",
        "test_np = test.to_numpy()\n",
        "print(train_np)\n",
        "print(test_np)\n",
        "model.fit(train_np, test_np, epochs=10, batch_size=32)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.54957224e+12 3.39997000e+03 3.40331000e+03 ... 3.39985491e+03\n",
            "  6.24703200e+02 4.21600000e+03]\n",
            " [1.54957584e+12 3.39707000e+03 3.40000000e+03 ... 3.39695997e+03\n",
            "  4.25889042e+02 3.76500000e+03]\n",
            " [1.54957944e+12 3.39999000e+03 3.40180000e+03 ... 3.39818848e+03\n",
            "  3.14319555e+02 3.63500000e+03]\n",
            " ...\n",
            " [1.55634024e+12 5.27946000e+03 5.30380000e+03 ... 5.28873195e+03\n",
            "  7.36375706e+02 5.96800000e+03]\n",
            " [1.55634384e+12 5.30300000e+03 5.32000000e+03 ... 5.31021131e+03\n",
            "  7.74417616e+02 6.43900000e+03]\n",
            " [1.55634744e+12 5.31381000e+03 5.31953000e+03 ... 5.31251703e+03\n",
            "  4.73888057e+02 5.11900000e+03]]\n",
            "[[3399.99]\n",
            " [3395.55]\n",
            " [3394.28]\n",
            " ...\n",
            " [5314.62]\n",
            " [5316.07]\n",
            " [5301.53]]\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/10\n",
            "1883/1883 [==============================] - 0s 81us/sample - loss: 18749635.5475 - mean_absolute_error: 4284.7227\n",
            "Epoch 2/10\n",
            "1883/1883 [==============================] - 0s 48us/sample - loss: 18749635.6739 - mean_absolute_error: 4284.7222\n",
            "Epoch 3/10\n",
            "1883/1883 [==============================] - 0s 44us/sample - loss: 18749635.6091 - mean_absolute_error: 4284.7217\n",
            "Epoch 4/10\n",
            "1883/1883 [==============================] - 0s 45us/sample - loss: 18749635.6006 - mean_absolute_error: 4284.7217\n",
            "Epoch 5/10\n",
            "1883/1883 [==============================] - 0s 47us/sample - loss: 18749635.4201 - mean_absolute_error: 4284.7222\n",
            "Epoch 6/10\n",
            "1883/1883 [==============================] - 0s 45us/sample - loss: 18749635.4870 - mean_absolute_error: 4284.7227\n",
            "Epoch 7/10\n",
            "1883/1883 [==============================] - 0s 45us/sample - loss: 18749635.6134 - mean_absolute_error: 4284.7222\n",
            "Epoch 8/10\n",
            "1883/1883 [==============================] - 0s 47us/sample - loss: 18749635.5443 - mean_absolute_error: 4284.7217\n",
            "Epoch 9/10\n",
            "1883/1883 [==============================] - 0s 47us/sample - loss: 18749635.7801 - mean_absolute_error: 4284.7217\n",
            "Epoch 10/10\n",
            "1883/1883 [==============================] - 0s 49us/sample - loss: 18749635.5932 - mean_absolute_error: 4284.7222\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1c18a1a828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    }
  ]
}